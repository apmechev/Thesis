\section{Administrata}

\subsection{Motivation and Objectives}

The goal of this work is to create a system to quickly, easily and reliably process data from the LOFAR radio telescope. Our software needs to be able to process tens of terabytes of data per day automatically, and be easy to integrate with different infrastructure providers.   

\subsection{Software Contributions}
 
For this work, we built several software packages to define, launch, and orchestrate jobs on a high throughput cluster. The software packages built are GRID\_LRT\footnote{\url{https://github.com/apmechev/GRID_LRT/}}, GRID\_PiCaS\_Launcher\footnote{\url{https://github.com/apmechev/GRID_PiCaS_Launcher}} and AGLOW\footnote{\url{https://github.com/apmechev/AGLOW}}. They are available on GitHub and their documentation is hosted on ReadTheDocs. 


\subsection{Statement of Originality}

I hereby certify that the contents of this thesis is my own original work, consisting of six manuscripts submitted to peer reviewed journals and conferences. This thesis and the works therein have not been submitted to any other degree program. Finally, I certify that the intellectual content in this work and all software referenced therein are of my own work unless explicitly cited otherwise, and that all assistance in compiling this work has been properly acknowledged.

\subsection{Publications}

Chapter ~\ref{ch:LOFAR_DSP} describes our first attempts to do large-scale distributed LOFAR processing on a shared infrastructure. We detail our successes with the LOFAR Radio Recombination Lines and Pre-Processing Pipelines, our software set-up as well as the limitations and future uses of this platform.  


Chapter ~\ref{ch:GRID_LRT} is our implementation for portable LOFAR processing on a massive scale. We show early results encapsulating LOFAR processing pipelines, and discuss future uses on other clusters. It is based on:  \fullcite{mechev17}.

Chapter ~\ref{ch:pipeline_collector} discusses our work collecting detailed performance statistics from automated LOFAR processing. It is based on: \fullcite{mechev_pipeline_collector}.

Chapter ~\ref{ch:AGLOW} describes the capabilities of the initial workflow manager for automatic processing of LOFAR SKSP data. It shows several different scientific workflows and is based on: \fullcite{ieee_AGLOW}.

Chapter ~\ref{ch:Scalability_model}  describes a parametric model of resource usage for the LOFAR \texttt{prefactor} pipeline. We discuss difficulties that may arise from scaling LOFAR data, as well the utility of our modelling method for SKA-size data. This chapter is  based on \fullcite{parameteric_model}.

Finally, Chapter ~\ref{ch:AGLOW_CI} demonstrates the flexibility of our AGLOW software by implementing a full Continuous Integration pipeline for LOFAR software containers and LOFAR scientific pipelines. This pipeline can verify software pipelines against a test data set, and can be used to track the data quality of data products as the processing software evolves. This work is submitted to the IEEE e-Science Conference 2019.
