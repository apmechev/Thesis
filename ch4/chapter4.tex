%%%% This is file `elsarticle-template-1-num.tex',
%%%%
%%%% Copyright 2009 Elsevier Ltd
%%%%
%%%% This file is part of the 'Elsarticle Bundle'.
%%%% ---------------------------------------------
%%%%
%%%% It may be distributed under the conditions of the LaTeX Project Public
%%%% License, either version 1.2 of this license or (at your option) any
%%%% later version.  The latest version of this license is in
%%%%    http://www.latex-project.org/lppl.txt
%%%% and version 1.2 or later is part of all distributions of LaTeX
%%%% version 1999/12/01 or later.
%%%%
%%%% Template article for Elsevier's document class `elsarticle'
%%%% with numbered style bibliographic references
%%%%
%%%% $Id: elsarticle-template-1-num.tex 149 2009-10-08 05:01:15Z rishi $
%%%% $URL: http://lenova.river-valley.com/svn/elsbst/trunk/elsarticle-template-1-num.tex $
%%%%
%%\documentclass[preprint,5p]{elsarticle}
%%
%%%% Use the option review to obtain double line spacing
%%%% \documentclass[preprint,review,12pt]{elsarticle}
%%
%%%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%%%% for a journal layout:
%%%% \documentclass[final,1p,times]{elsarticle}
%%%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%%%% \documentclass[final,3p,times]{elsarticle}
%%%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%%%% \documentclass[final,5p,times]{elsarticle}
%%%% \documentclass[final,5p,times,twocolumn]{elsarticle}
%%\usepackage{natbib}
%%\bibliographystyle{abbrvnat}
%%\setcitestyle{authoryear,open={(},close={)}} %Citations bracketed with ()
%%\setcitestyle{citesep={;}} %Makes multiple citations with ;
%%%% The graphicx package provides the includegraphics command.
%%\usepackage{graphicx}
%%\usepackage{footnote}
%%\usepackage{epsfig}
%%
%%\makesavenoteenv{tabular}
%%\makesavenoteenv{table}
%%
%%
%%\usepackage{url}
%%%% The amssymb package provides various useful mathematical symbols
%%\usepackage{amssymb}
%%%% The amsthm package provides extended theorem environments
%%%% \usepackage{amsthm}
%%
%%\usepackage{dcolumn}% Align table columns on decimal point
%%\usepackage{bm}% bold math
%%%% The lineno packages adds line numbers. Start line numbering with
%%%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%%%% for the whole article with \linenumbers after \end{frontmatter}.
%%\usepackage[switch]{lineno}
%%%\linenumbers
%%
%%\usepackage{caption}
%%\usepackage{subcaption}
%%%% natbib.sty is loaded by default. However, natbib options can be
%%%% provided with \biboptions{...} command. Following options are
%%%% valid:
%%
%%%%   square -  square brackets are used   [option]
%%%%   curly  -  curly braces are used      {option}
%%%%   angle  -  angle brackets are used    <option>
%%%%   semicolon  -  multiple citations separated by semi-colon
%%%%   colon  - same as semicolon, an earlier confusion
%%%%   comma  -  separated by comma
%%%%   numbers-  selects numerical citations
%%%%   super  -  numerical citations as superscripts
%%%%   sort   -  sorts multiple citations according to order in ref. list
%%%%   sort&compress   -  like sort, but also compresses numerical citations
%%%%   compress - compresses without sorting
%%%%
%%%% \biboptions{comma,round}
%%
%%% \biboptions{}
%%\journal{Astronomy and Computing}
%%
%%% % 
%%\begin{document}\sloppy
%%
%%\begin{frontmatter}
%%
%%%% Title, authors and addresses

%\addcontentsline{toc}{chapter}{Pipeline Collector}

\chapter[Pipeline Collector]{\textit{Pipeline Collector}: Gathering performance data for distributed astronomical pipelines}\label{ch:pipeline_collector}
\setcounter{footnote}{0}

%peedup real life pipelines performance automatic measurements radio astronomy
%\thanks{A footnote to the article title}%X
\author{Alexandar P. Mechev$^a$ }
%\ead{apmechev@strw.leidenuniv.nl}

% \altaffiliation[Also at ]{Physics Department, XYZ University.}%Lines break automatically or can be forced with \\
\author{Aske Plaat$^b$}%
\author{J.B. Raymond Oonk$^a$$^,$$^c$}%
\author{Huib T. Intema$^a$}%
\author{Huub J.A. R\"ottgering$^a$}%

\date{\today}% It is always \today, today,
%\address{$^a$Leiden Observatory, Niels Bohrweg 2, 2333 CA Leiden, the Netherlands}
%\address{$^b$Leiden Institute of Advanced Computer Science, Niels Bohrweg 1, 2333 CA Leiden, the Netherlands}
%\address{$^c$ASTRON,  Oude Hoogeveensedijk 4, 7991 PD Dwingeloo, the Netherlands}

\begin{abstract}
Modern astronomical data processing requires complex software pipelines to process ever growing datasets. For radio astronomy, these pipelines have become so large that they need to be distributed across a computational cluster. This makes it difficult to monitor the performance of each pipeline step. To gain insight into the performance of each  step, a performance monitoring utility needs to be integrated with the pipeline execution. In this work we have developed such a utility and integrated it with the calibration pipeline of the Low Frequency Array, LOFAR, a leading radio telescope. We tested the tool by running the pipeline on several different compute platforms and collected the performance data. Based on this data, we make well informed recommendations on future hardware and software upgrades. The aim of these upgrades is to accelerate the slowest processing steps for this LOFAR pipeline. The \textit{pipeline\_collector} suite is open source and will be incorporated in future LOFAR pipelines to create a performance database for all LOFAR processing. 
% \begin{description}

% \item[Prefactor]
% The \texttt{LOFAR} pre-factor pipeline prepares LOFAR Observations for creating high fidelity images. 
% \end{description}
\end{abstract}

%\begin{keyword}
%Radio Astronomy \sep Performance Analysis \sep Profiling \sep High Performance Computing
%\end{keyword}

%\end{frontmatter}

%\maketitle\makesavenoteenv{tabular}

%
%\tableofcontents
%\linenumbers

\section{\label{sec:ch4_intro}Introduction }
\setcounter{footnote}{0}

Astronomical data often requires significant processing before it is considered ready for scientific analysis. This processing is done increasingly by complex and autonomous software pipelines, often consisting of numerous processing steps, which are run without user interaction. It is necessary to collect performance statistics for each pipeline step. Doing so will enable scientists to discover and address software and hardware inefficiencies and produce scientific data at a higher rate. To identify these inefficiencies, we have extended the performance monitoring package \textit{tcollector}\footnote{https://github.com/OpenTSDB/tcollector}\citep{tcollector}. The resulting suite, \textit{pipeline\_collector}, makes it possible to use \textit{tcollector} to record data for complex pipelines. We have used a leading radio telescope as the test case for the \textit{pipeline\_collector} suite. The discoveries made with our software will help remove bottlenecks and suggest hardware requirements for current and future processing clusters. We summarize our findings in Table \ref{table:ch4_results} in Section \ref{sec:ch4_results}.

Over the past two decades, processing data in radio astronomy has increasingly moved from personal machines to large compute clusters. Over this time, radio telescopes have undergone upgrades in the form of wide band receivers and upgraded correlators \citep{lofarcobalt,gmrt_upgrade}. In addition, several aperture synthesis arrays such as the Low Frequency Array \citep[LOFAR,][]{LOFAR}, Murchison Widefield Array \citep[MWA][]{MWA,mwa2} and MeerKAT \citep{meerkat} have begun observing the radio sky, leading to an increase of data rates by up to 3 orders of magnitude \citep{mwa_data_size,meerkat_size}.

As the data acquisition rate has increased, data size has entered the Petabyte regime, and processing requirements increased to millions of CPU-hours. In order for processing to match the acquisition rate, the data is increasingly processed at large clusters with high-bandwidth connections to the data. An important case where data processing is done at a high throughput cluster is the LOFAR radio telescope.

The LOFAR telescope is a European low frequency aperture synthesis radio telescope centered in the Netherlands with stations stretching across Europe. This aperture synthesis telescope requires significant data processing before producing scientific images \citep{lofar_prefactor,Wendy_bootes,tassesmirnov,oonk_2014}. In this work, we will use our performance monitoring utility, \textit{pipeline\_collector}\footnote{https://gitlab.com/apmechev/pipeline\_collector.git}, to study the first half of the LOFAR processing, the Direction Independent (hereafter  DI) pipeline. 

One major project for the LOFAR telescope is the Surveys Key Science Project (SKSP) \citep{lotss}. This project consists of more than 3000 observations of 8 hours each, 600 of which have been observed. These observations need to be processed by a DI pipeline, the results of which are calibrated by a Direction Dependent (DD) pipeline. The DI pipeline is implemented in the software package \textit{prefactor}\footnote{available at \protect\url{https://github.com/lofar-astron/prefactor}}. The \textit{prefactor} pipeline is itself split into four stages and implemented at the SURFsara Grid location at the Amsterdam e-Science centre \citep{SurfSara,mechev}. The automation and simple parallelization has decreased the run time per dataset from several days to six hours, making it comparable to the observation rate. To better understand and optimize the performance of the \textit{prefactor} pipeline, we require detailed performance information for all steps of the processing software. We have developed a utility to gather this information for data processing pipelines running on distributed compute systems. 

In this work, we will use the \textit{pipeline\_collector} utility to study the LOFAR \textit{prefactor} pipeline and suggest optimization based on our results. To test the software on a diverse set of hardware, we will set up the monitoring package on four different computers and collect data on the pipeline's performance. Using this data, we discuss several aspects of the LOFAR software which we present in Table \ref{table:ch4_results}. Finally we discuss the broader context of these optimizations in relation to the LOFAR SKSP project and touch on the integration of \textit{pipeline\_collector} with the second half of the data processing pipeline, the DD calibration and imaging. 
    
 \begin{table*}[!htb]
 \begin{center}
  \begin{tabular}{ l | p{130mm} }
    \hline
    Result \# & Description  \\ \hline
    \hline
    \textbf{R1} & Native compilation of the software performs comparably to pre-compiled binaries on two test machines. \\ \hline
    \textbf{R2} &  The processing steps do not appear to accelerate significantly on a faster processor or with larger cache size. \\ \hline
    \textbf{R3} & Both calibration steps (\textit{calib\_cal} and \textit{gsmcal\_solve}) show linear correlation between speedup and memory bandwidth. \\ \hline
    \textbf{R4} &  Disk read/write speed does not affect the completion time of the slowest steps. \\ \hline
    \textbf{R5} & Both calibration steps do not use large amounts of RAM despite processing data on the order of Gigabytes. \\ \hline
    \textbf{R6} & The \textit{calib\_cal} step can suffer up to 20\% of Level 1 Instruction Cache misses, while gsmcal only has 5\% of these misses. \\ \hline
    \textbf{R7} & Both calibration steps are impacted by Level 2 Cache eviction at comparable rates. \\ \hline
    \textbf{R8} & The \textit{calib\_cal} step stalls on resources 70\% of cycles while the gsmcal step only 30\% of them. \\ \hline
    \textbf{R9} & The \textit{calib\_cal} uses the CPU at full efficiency for only 10 \% of the CPU cycles. \\ \hline
    \hline
  \end{tabular}   
  \caption{A table of all the results presented in Section \ref{sec:ch4_results}.}
  \label{table:ch4_results}
   \end{center}
 \end{table*}
 
 
\subsection{Related Work}\label{sec:ch4_related}

Scientific fields that need to process large data sets employ some type of data processing pipelines.  Such pipelines include e.g. solar imaging \citep{solar_pipeline}, neuroscience imaging \citep{optimize_pipeline} and infrared astronomy \citep{herschel}. While these pipelines often log the start and finishing times of each step (using tools such as pegasus-kickstart \citep{kickstart}), they do not collect detailed time series performance data throughout the run. 

At a typical compute cluster the performance of every node in a distributed systems is monitored using utilities, such as Ganglia \citep{ganglia}. These tools only monitor the global system performance. 
If one is interested in specific processes, then the Linux procfs \citep{procfs} is used. The procfs system can be used to analyse the performance of individual pipeline steps. Likewise, the Performance API \citep[PAPI,][]{papi} is a tool which collects detailed low level information on the CPU usage per process. Collecting detailed statistics at the process level is required to understand and optimize the performance of the LOFAR pipeline and we will integrate PAPI into \textit{pipeline\_collector} in the future. Finally, DTrace\citep{dtrace} is a Sun Microsystems tool which makes it possible to write profiling scripts that access data from the kernel and can be used to monitor process or system performance at run time with minimal overhead. As DTrace was not installed on either of the processing clusters, we have not used it to monitor the pipeline's performance. 

The Linux procfs system and PAPI record data which is already made available by the Linux kernel. This option incurs insignificant overhead as it uses data the kernel and processor already log. Likewise PAPI reads performance counters that the CPU automatically increments during processing. These profiling utilities can run concurrently with the scientific payload without using more than 1-2\% of system resources. Their low overhead is why we choose to use them to collect performance data. 

Other tools for performance analysis such as Valgrind \citep{valgrind} collect very detailed performance information. This comes at the expense of execution time: running with Valgrind, the processing time slows by up to two orders of magnitude. As such, we do not use Valgrind along the LOFAR software. 

\input{ch4/section_2}

\section{LOFAR Prefactor Test Case}\label{sec:ch4_results}
  
With the test set described in Section \ref{sec:ch4_methods}, we aim to understand processing bottlenecks in the \textit{prefactor} pipeline and make informed decisions on future hardware and software upgrades. To do so, we processed a sample observation at institutes that typically process LOFAR data. 

From the data collected by processing the sample observation, we determined the slowest pipeline steps. These steps were the \textit{calib\_cal} and \textit{gsmcal\_solve}, seen in Figure \ref{fig:ch4_4_steps_pies}. The \textit{calib\_cal} step is implemented by the software \texttt{bbs-reducer} \citep{cookbook,bbs_selfcal} and the \textit{gsmcal\_solve} step is implemented by \texttt{NDPPP} \citep{cookbook,lofar_NDPPP}. Both \texttt{bbs-reducer} and \texttt{NDPPP} are part of the LOFAR software suite.

We collected performance statistics using the \textit{pipeline\_collector} suite as discussed in Section \ref{sec:ch4_methods}. The runtime of the slowest \textit{prefactor} steps on the four machines is shown in figure \ref{fig:ch4_calibcal_fitclock_bars}. The results discovered using \textit{pipeline\_collector} are listed in Table \ref{table:ch4_results} and discussed in Section \ref{sec:ch4_res_tcoll}. Using the PAPI interface (discussed in Section \ref{sec:ch4_papi2}) CPU performance data was collected. The results from this test are detailed in Section \ref{sec:ch4_PAPI}.


 
We will present a number of insights into the performance of the LOFAR software collected by the profiling suite. The results are presented in Table \ref{table:ch4_results} and are grouped in three main areas. The effect of compilation on the runtime was result \textbf{R1}. The set of results \textbf{R2}, \textbf{R3}, \textbf{R4} and \textbf{R5} were obtained using the \textit{pipeline\_collector} package. Results  \textbf{R6}, \textbf{R7}, \textbf{R8} and \textbf{R9} were collected with the PAPI package, which will be integrated into \textit{pipeline\_collector} in the future.  

\subsection{Pre-compiled vs native compilation}
 \footnotetext[7]{benchmarked using $dd$}
 \footnotetext{sequential disk read, benchmarked using \texttt{fio} - flexible I/O tester: \newline \newline \texttt{fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod\_reduce=1 --name=test --filename=test --bs=4k --iodepth=256 --size=4G --readwrite=read --ramp\_time=4} \newline } 

The performance trade-off between pre-compiled and native compilation was studied first. The majority of the processing for the LOFAR SKSP Project \citep{lotss} is done at the SURFsara \textsc{gina} cluster in Amsterdam. This location is part of the European Grid Initiative (EGI)\citep{SurfSara}. At this location, software is deployed by compiling on a virtual machine and mounting it on all worker nodes through the CernVM FileSystem (CVMFS) service \citep{cvmfs}. The CVMFS server allows any client to mount a fully compiled LOFAR installation, making it easy to distribute and version control the software within and outside of SURFsara. An alternative is to locally compile the LOFAR packages on each cluster. The performance of the natively compiled\footnote{The software was compiled using \texttt{-march=native} and \texttt{-O3} compilation flags. On the laptop, gcc resolves \texttt{-march=native} as \texttt{broadwell}. The CVMFS installation resolves \texttt{-march=native} as \texttt{core-avx-i}.} vs CVMFS installations was compared on the laptop test machine using \textit{pipeline\_collector}. In order to validate this result, the two compilations of the same software were also tested at the Data Science Lab at the Leiden Institute of Advanced Computer Science (LIACS)\footnote{https://www.universiteitleiden.nl/en/science/computer-science/about-us/our-facilities}. 
 
An interesting discovery is that the LOFAR software did not process data faster when compiled natively. This is despite the fact that the local install was compiled with advanced processor instructions available on the host machine.  Figure \ref{fig:ch4_cvmfs_native} shows a histogram of its processing time with the two different compilation options for the \textit{calib\_cal} software running on the sample dataset. The same test was done for the software performing the gain calibration (\textit{gsmcal\_solve}), seen in Figure \ref{fig:ch4_cvmfs_native_gsm}. The result of this experiment is shown in Figures \ref{fig:ch4_cmvfs1_calib} and \ref{fig:ch4_cmvfs1_gsmcal}.  The software compiled at SURFsara showed a minor improvement for the \textit{calib\_cal} step on the laptop machine, however this improvement is not seen on the computational cluster node. 

Overall, the software for both steps show no significant improvement when compiled natively. This is result \textbf{R1} in Table \ref{table:ch4_results}. The second run at LIACS also confirms this result for both steps (Figures \ref{fig:ch4_cmvfs2_calib} and \ref{fig:ch4_cmvfs2_gsmcal}). This result suggests that the slowest \textit{prefactor} steps are not optimized for modern processors. 

%\textit{suggesting that a CVMFS install is a reasonable software deployment strategy for LOFAR.} \textbf{wrap back into how the software was used in conclusions?}

\begin{figure*}
  \centering
   \begin{subfigure}{.45\linewidth}
    \includegraphics[width=\textwidth]{ch4/figures/fig3/figure3_calibcal.pdf}
    \caption{calib\_cal}
	\label{fig:ch4_calib_cal_bar}
 \end{subfigure}%
 \begin{subfigure}{.45\linewidth}
  \includegraphics[width=\textwidth]{ch4/figures/fig3/fixed-figure3_gsmcal.pdf}
  \caption{\textit{gsmcal\_solve} }
  \label{fig:ch4_gsmcal_bar}
 \end{subfigure}
    \caption[Job completion times for two processing steps tested on four hardware setups]{Job completion times for \textit{calib\_cal} and \textit{gsmcal\_solve} steps tested on four hardware setups. The \textit{calib\_cal} step ran 244 times. The \textit{gsmcal\_solve} ran 24 times as the data is concatenated from 244x1 to 24x10 sets.  The step with the longest latency is \textit{gsmcal\_solve} while \textit{calib\_cal} consumes a comparable number of core-hours over 244 jobs. } 
  \label{fig:ch4_calibcal_fitclock_bars}
\end{figure*}

\begin{figure*}
  \centering
     \begin{subfigure}{.45\linewidth}
    \includegraphics[width=\linewidth]{ch4/figures/ppr2_calib_local.png}
    \caption{Two compilation options on a Laptop}
	\label{fig:ch4_cmvfs1_calib}
    \end{subfigure}%
    \begin{subfigure}{.45\linewidth}
     \includegraphics[width=\linewidth]{ch4/figures/ppr2_calib_cluster.png}
    \caption{Two compilation options on cluster node}
	\label{fig:ch4_cmvfs2_calib}
    \end{subfigure}%
      \caption[Speed comparison between natively and remotely compiled software for the 'calib\_cal' step.]{Difference in processing time for \textit{calib\_cal} when compiled remotely and natively. \textit{calib\_cal} was run 244 times with the native software and 40 times with the CVMFS compilation. Two tests were done, one on the personal laptop (\ref{fig:ch4_cmvfs1_calib}) and one on a cluster node at the LIACS Data Science Lab (\ref{fig:ch4_cmvfs2_calib}). The test on a cluster node shows no significant difference in runtime between compilation options. The laptop test suggests that the remotely compiled software may run 5\% faster than the local compilation. } 
	\label{fig:ch4_cvmfs_native}
\end{figure*}


\begin{figure*}
  \centering
     \begin{subfigure}{.45\linewidth}
    \includegraphics[width=\linewidth]{ch4/figures/ppr2_gsm_local.png}
    \caption{Two compilation options on a Laptop}
	\label{fig:ch4_cmvfs1_gsmcal}
    \end{subfigure}%
    \begin{subfigure}{.45\linewidth}
     \includegraphics[width=\linewidth]{ch4/figures/ppr2_gsm_cluster.png}
    \caption{Two compilation options on cluster node}
	\label{fig:ch4_cmvfs2_gsmcal}
    \end{subfigure}%
      \caption[Speed comparison between natively and remotely compiled software for the 'gsmcal\_solve' step.]{Difference in processing time for \textit{gsmcal\_solve} when compiled remotely and natively. \textit{gsmcal\_solve} was run 50 times with the native software and 120 times with the CVMFS compilation. Two tests were done, one on the personal laptop (\ref{fig:ch4_cmvfs1_gsmcal}) and one on a cluster node at the LIACS Data Science Lab (\ref{fig:ch4_cmvfs2_gsmcal}). Just like with the \textit{calib\_cal} step, the \textit{gsmcal\_solve} step also doesn't accelerate significantly when natively compiled.} 
	\label{fig:ch4_cvmfs_native_gsm}
\end{figure*}

\subsection{Prefactor Runtime and Hardware Parameters}\label{sec:ch4_res_tcoll}

Next, we studied the dependence of runtime on different hardware parameters. With software that collects per-step performance statistics for the LOFAR pipeline, the dependence of the pipeline processing on hardware performance can be easily profiled and studied. Using \textit{pipeline\_collector} we determined the pipeline's slowest steps with respect to different hardware parameters. 

The system parameters studied here are the CPU speed, memory throughput, cache size and disk speed. Modern computers can have a complex memory hierarchy as demonstrated in Figure \ref{fig:ch4_mem_hiearch} \citep{mem_hiearch}. This is due to the cost trade-off between memory size and memory speed. Because of this trade-off, the full dataset is stored on disk, while the working set is placed in RAM. This is the data that the processor needs to access at the current time \citep{workingset}. The most frequently accessed parts of the data are stored in the CPU cache, which evicts the oldest data when full \citep{cache_eviction}. 

The CPU processing speed is faster than the RAM latency, so a hierarchy of caches exist. Caches store small subsets of the working set and have a fast connection to the processor. The fastest data link is between the CPU and the L1 Cache, with the link to RAM being slower and the disk read speed slower still. The limited memory capacity of the different levels of the memory hierarchy  as well as the throughput between them will lead to performance bottlenecks. These bottlenecks will lead to the processor waiting on memory. Such stalls lead to longer processing times.

\begin{figure}[ht!]
  \centering
    \includegraphics[width=0.5\linewidth]{ch4/figures/fig6/pyramid.png}
      \caption{A model of the memory hierarchy, as described in \citep{goto2008anatomy}. }
	\label{fig:ch4_mem_hiearch}
\end{figure}


\subsubsection{CPU}
The CPU speed is usually the primary factor determining how fast computations can be made. In general, a faster CPU will result in faster data processing. 

However, Fig. \ref{fig:ch4_calib_cal_CPU} shows that the runtime of the calibration of the calibrator does not strongly depend on the CPU frequency. While the test nodes at SURFsara and Leiden run at the same CPU frequency, running on a cluster node at SURFsara takes half the time as on a node at Leiden. Even more surprisingly, the \textit{gsmcal\_solve} step does not benefit significantly from a faster CPU, despite being the most computationally heavy \textit{prefactor} step (\textbf{R2}). This step does the gain calibration on the target field using the StEFCal algorithm \citep{stefcal}. Figure \ref{fig:ch4_gsmcal_CPU} shows only a slight improvement over faster CPU clock speeds for both steps. The correlation between completion time and CPU speed is similar for both steps.

\begin{figure*}
    \centering
\begin{subfigure}[b]{0.45\linewidth}
%\begin{subfigure}{.5\textwidth}
    \includegraphics[width=\linewidth]{ch4/figures/fig7/calibcalCPU.pdf}
      \caption{calib\_cal }
	\label{fig:ch4_calib_cal_CPU}
 \end{subfigure}%
 \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{ch4/figures/fig7/gsmcalCPU.pdf}
      \caption{\textit{gsmcal\_solve}}
	\label{fig:ch4_gsmcal_CPU}
 \end{subfigure}
 \label{fig:ch4_CPU_3_steps}
    \caption[Effect of CPU speeds on the bottle neck steps for the four test machines.]{Performance of the bottleneck steps compared with the CPU speeds of the four test machines. The values are the mean of 244 runs (Standard prefactor run) and the error bars show the 1-sigma of the distribution of the run time. } 

\hfill        %
\end{figure*}

\subsubsection{Cache}
The CPU has a hierarchy of caches consisting of Level 1, Level 2 Cache and LLC Cache. For the four processors tested, the Level 1 and 2 caches were all the same size, thus the only difference is the Last Level Cache (LLC or just Cache in Figure \ref{fig:ch4_mem_hiearch}). This cache stores data needed by the CPU, so the larger it is, the less the processor needs to wait for RAM to return data. 

In general, numerical codes benefit from larger cache sizes \citep{skadron1999branch,goto2008anatomy}. Interestingly,  figure \ref{fig:ch4_gsmcal_cache} suggests that the \textit{gsmcal\_solve} step does not exclusively depend on larger cache \textbf{R3} (Table \ref{table:ch4_results}). On the machines with a larger cache, the \textit{gsmcal\_solve} step completed processing as quickly as on the machines with smaller cache, even down to 8MB.  

\begin{figure*}
    \centering
    \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{ch4/figures/fig8/calibcal_LLC.pdf}
      \caption{calib\_cal }
	\label{fig:ch4_calib_cal_cache}
 \end{subfigure}%
 \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{ch4/figures/fig8/gsmcal_LLC.pdf}
      \caption{\textit{gsmcal\_solve}}
	\label{fig:ch4_gsmcal_cache}
 \end{subfigure}
 \label{fig:ch4_cache_3_steps}
    \caption[Effect of cache size on the bottle neck steps for the four test machines.]{Performance of the two bottleneck steps with respect to Last Level Cache size. The \textit{gsmcal\_solve} step shows no trend between cache size and completion time. The \textit{calib\_cal} step runs the fastest on the machine with the smallest cache.  } 

\end{figure*}

\subsubsection{RAM Bandwidth}

If the entire data set does not fit into cache, the software needs to transfer data from RAM to the CPU. In these cases,  \textit{prefactor} benefits from a fast bandwidth between the cache and RAM. For this study, the RAM throughput was benchmarked\footnote{Using the command \texttt{\$> dd if=/dev/zero of=/dev/shm/test  bs=1M count=2048}}. This command copies dummy data into system memory. As this utility exists on all Unix systems, this is a standardized benchmark of the RAM performance. 

\begin{figure*}
\centering
    \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{ch4/figures/fig9/calibcal_MEM.pdf}
      \caption{\textit{calib\_cal}}
	\label{fig:ch4_calib_cal_RAM}
 \end{subfigure}%
    \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{ch4/figures/fig9/gsmcal_MEM.pdf}
      \caption{\textit{gsmcal\_solve}}
	\label{fig:ch4_gamcal_RAM}
 \end{subfigure}
 \label{fig:ch4_ram_bandw}
    \caption[Effect of RAM throughput on the bottle neck steps for the four test machines.]{Performance of the two bottleneck steps and RAM bandwidth in GB/s. Both the \textit{calib\_cal} and \textit{gsmcal\_solve} steps show a trend of faster processing times on machines with higher RAM bandwidth. Both steps show a trend of decreasing processing time with increasing RAM throughput.} 
\end{figure*}

Figure \ref{fig:ch4_calib_cal_RAM} showed that higher bandwidth is correlated with a faster completion time for the \textit{calib\_cal} and \textit{gsmcal\_solve} steps (\textbf{R4}). The result is to be expected as the working set of these steps is 200MB and 1.0GB respectively, and cannot fit into cache readily, however it is loaded into RAM within the first 5 seconds of the run (Figure \ref{fig:ch4_VMRSS}), and is streamed from memory throughout the run. 

\subsubsection{Disk Read speeds}

The slowest link in the memory hierarchy is the disk read speed. For the \textit{calib\_cal} step, the entire data is loaded into memory during the first few seconds of the run, after which the disk only becomes important when the results need to be written out. The \textit{gsmcal\_solve} step streams data from the disk to memory throughout the entire run.  The plot of disk read speeds (Fig. \ref{fig:ch4_gsmcal_HDD}) also shows that a faster disk does not speed up the slowest step \textbf{R5}. To verify that disk throughput was not the limiting factor, the entire dataset (25 GB) was moved to main memory (using /dev/shm).  The resulting runtime for both bottleneck steps did not change.  

The calibration steps both stored less than 200MB of data in memory throughout their run. Figure \ref{fig:ch4_VMRSS} shows the time-series of the total memory used by these steps. The \textit{calib\_cal} step uses only 200MB of memory and \textit{gsmcal\_solve} only 35MB. While the \textit{gsmcal\_solve} step works on a 1GB dataset, it streams the data in memory and thus does not require 1GB of RAM. Alternatively, the \textit{calib\_cal} step loads the entire (200MB) dataset into memory for the entire duration of the run. The RAM usage time-series in Figure \ref{fig:ch4_VMRSS} show that the RAM is filled for the first 5 seconds of the run, further confirming that the processing is effectively independent from disk speed. 


\begin{figure*}
  \centering
   \begin{subfigure}{.45\textwidth}
    \includegraphics[width=\textwidth]{ch4/figures/fig10/calibcal_vmrss.png}
      \caption{\textit{calib\_cal} }
	\label{fig:ch4_calib_cal_VMRSS}
 \end{subfigure}%
 \begin{subfigure}{.45\textwidth}
    \includegraphics[width=\textwidth]{ch4/figures/fig10/gsmcal_vmrss.png}
      \caption{\textit{gsmcal\_solve}}
	\label{fig:ch4_fitclock_VMRSS}
 \end{subfigure}
    \caption[Time series of the Virtual Memory Resident Set Size]{Time series of the Virtual Memory Resident Set Size. This is the amount of data stored in RAM (in kB) during the \textit{calib\_cal} and \textit{gsmcal\_solve} steps. Both steps show the same amount of memory use on all test machines. Additionally, after a brief loading of data, the memory usage remains constant until processing is finished. }
 \label{fig:ch4_VMRSS}
\end{figure*}

\begin{figure}
  \centering
   \begin{subfigure}{.45\textwidth}
    \includegraphics[width=\textwidth]{ch4/figures/fig11/calibcal_HDD.eps}
      \caption{calib\_cal }
	\label{fig:ch4_calib_cal_HDD}
 \end{subfigure}
  \begin{subfigure}{.45\textwidth}
    \includegraphics[width=\textwidth]{ch4/figures/fig11/GSMcal_HDD.eps}
      \caption{\textit{gsmcal\_solve}}
	\label{fig:ch4_gsmcal_HDD}
 \end{subfigure}
 \label{fig:ch4_HDD_2_steps}
    \caption[Performance of the two bottleneck steps and Disk bandwidth in MB/s.]{Performance of the two bottleneck steps and Disk bandwidth in MB/s. There is no correlation between the Disk read speed and the Runtime of the steps.} 
\end{figure}


\section{CPU Utilization Tests with PAPI}\label{sec:ch4_PAPI}

To gain more fine grained data on the CPU utilization, the \textit{calib\_cal} and \textit{gsmcal\_solve} steps were tested with the PAPI package.  We ran this package as a test, to determine whether collecting PAPI data is helpful in understanding pipeline performance.  PAPI can record data such as cache performance, branch prediction rate, fraction of memory/branch instructions and others. This data is complementary to the procfs information, which is collected by the Linux kernel. As the collected data was useful in understanding the \textit{prefactor} pipeline, we will include PAPI in the \textit{pipeline\_collector} suite in the future. In the following sections we will discuss the results obtained for the \textit{calib\_cal} and \textit{gsmcal\_solve} steps.

\subsection{Level 1 Data Misses}

The Level 1 Cache is split into cache for instructions and data. For all our test hardware the L1 Data cache is 32 kB, and has a direct link to the processor's computational units \citep{haswell}. The processor collects information logging how many times data requested by the CPU is not located into the L1 Data cache. This counter is called the Level 1 Data Cache Miss rate. To resolve this type of cache miss, the data needs to be fetched from L2 Cache. When this happens, the processor has to wait for the requested data. \textbf{R7}: The recorded L1 data misses in Figure \ref{fig:ch4_L1Dm}, show that the software performing the \textit{calib\_cal} step  misses 20\% of its L1 data cache requests, while the software implementing the \textit{gsmcal\_solve} step misses less than 5\% of L1 Cache requests. These cache misses often happens in multi-threaded applications where there are instructions shared by multiple threads on the same cache line \citep{cache_opt}. 

\begin{figure}
  \centering
      \begin{subfigure}{.45\textwidth}
      \includegraphics[width=\textwidth]{ch4/figures/L1D_miss.png}
      \caption{Level 1 Data cache misses }
	\label{fig:ch4_L1Dm}
    \end{subfigure}
    \begin{subfigure}{.45\textwidth}
    \includegraphics[width=\textwidth]{ch4/figures/L2I_miss.png}
      \caption{Level 2 Instruction cache misses }
	\label{fig:ch4_L2Im}
  \end{subfigure}
    \caption[Cache miss rates for the bottlenexk steps, executed on the SURFsara gina cluster.]{Cache miss rates for \textit{calib\_cal} and \textit{gsmcal\_solve}, executed on the SURFsara gina cluster. The cache is split into instruction and data caches. The figures above show the difference in number of cache misses for both instruction cache and data cache for the slowest \textit{prefactor} steps. \textit{calib\_cal} suffers significantly more Data cache misses than \textit{gsmcal\_solve} while the two steps undergo similar instruction Cache misses.  }
\end{figure}


\subsection{Level 2 Instruction Misses}

Unlike the Level 1 cache, Level 2  cache stores data and instructions in the same location. When the cache is full, it evicts the last used element in order to make space for newly requested data. PAPI also counts these eviction events. 
Figure \ref{fig:ch4_L2Im} shows that for both steps, between 50 and 70\% of L2 requests for an instruction do not match the contents of L2 Cache. This is significantly more than the applications benchmarked in \citep[Table 2]{cache_misses}. Because both steps process data of considerable size, the large amount of data required can evict instructions from the L2 cache (insight number \textbf{R7} in table \ref{table:ch4_results}). 

\subsection{Resource Stalls}

Modern processors have multiple computational pipelines on chip, in order to process data in parallel \citep{pipeline_x86}. There are times when the processor's internal pipeline needs to wait for other instructions to finish. When this happens, it flags that it has 'stalled on a resource'. These resource stall cycles are also recorded by PAPI and represented as a percentage of total cycles. From figure \ref{fig:ch4_rstall}, it can be seen that \textit{calib\_cal} stalls on 70\% of the processor cycles, while  \textit{gsmcal\_solve} only on 33\% of cycles (\textbf{R8}). 

The Full Issue Cycles counter indicates the percentage of processor cycles, in which the theoretical maximum number of instructions are executed. During these cycles, the software uses the CPU optimally. The full issue cycles counter (Fig. \ref{fig:ch4_full_issue}) also shows the difference in efficiency between the \textit{calib\_cal} and \textit{gsmcal\_solve} step  (\textbf{R9}), with the former only working at peak efficiency for 10\% of the processor cycles.

\begin{figure}
  \centering
      \begin{subfigure}{.45\textwidth}
      \includegraphics[width=\textwidth]{ch4/figures/rstall.png}
      \caption{Resource Stall Cycles}
	\label{fig:ch4_rstall}
    \end{subfigure}
    \begin{subfigure}{.45\textwidth}
    \includegraphics[width=\textwidth]{ch4/figures/full_issue.png}
      \caption{Full Issue cycles }
	\label{fig:ch4_full_issue}
  \end{subfigure}
  \label{fig:ch4_rr}
    \caption[Resource stall cycles and Full Instruction Issue cycles.]{Resource stall cycles and Full Instruction Issue cycles. The two steps were  executed on the SURFsara gina cluster. }
\end{figure}

The plots in Figures \ref{fig:ch4_rstall} and \ref{fig:ch4_full_issue} indicate that the \textit{calib\_cal} step does not use the internal CPU pipelines efficiently leading to waiting on resources and sub-optimal use of the CPU's Computational Units.

\section{Discussions and Recommendations}

With an increase of data acquisition rates and data complexity in radio astronomy, it is becoming important to thoroughly understand and optimize the performance of processing pipelines. Using \textit{pipeline\_collector}, data can be collected for each pipeline step without altering the processing software. We store this data in a time-series database. The collected data can be studied to help researchers understand the pipeline performance for different processing parameters, datasets, and on different hardware. The \textit{pipeline\_collector} suite is easy to deploy for mature pipelines and has minimal impact on pipeline performance. Typical CPU usage is $<$0.2\% with a memory footprint of $\sim$ 1-10 MB.

Creating a performance model with the collected data will allow us to to optimize future clusters for LOFAR data processing. Doing so is necessary given the current data throughput, number of observations and time-line of the SKSP project. Similar issues will be encountered with upcoming radio telescopes \citep{meerkat_ska_size}.


To showcase the power of the pipeline\_collector suite, the LOFAR \textit{prefactor} pipeline was run through a single data set on three clusters and a personal machine. A number of insights were made using the high resolution timing data collected from this package (such as in Figure \ref{fig:ch4_VMRSS}) and are listed in Table \ref{table:ch4_results}. In the future, we'll apply the \textit{pipeline\_collector} software to the more complex LOFAR DD pipeline, \textit{ddf-pipeline}\footnote{https://github.com/mhardcastle/ddf-pipeline}. 

The slowest processing steps for the \textit{prefactor} pipeline were identified as the \textit{calib\_cal} and \textit{gsmcal\_solve} steps. While the data can fit into the RAM for all of the processing machines, it is much larger than the processor's internal cache (Figure \ref{fig:ch4_mem_hiearch}).  The discoveries made concerned the memory hierarchy in Figure \ref{fig:ch4_mem_hiearch}. Results labeled \textbf{R2}, \textbf{R8} and \textbf{R9} related to the CPU performance; \textbf{R2}, \textbf{R6} and \textbf{R7} related to the Cache performance; \textbf{R3} and \textbf{R5} related to the Memory usage and \textbf{R4} discussed the Disk speed. 

Faster processors did not accelerate the \textit{gsmcal\_solve} step significantly, as this step streams data between the RAM and CPU. As the CPU speed increases, streaming applications become bottlenecked by the throughput of data into the CPU from RAM. As the \textit{gsmcal\_solve} algorithm iteratively calibrates chunks of the data, these chunks need to be loaded from disk once, however they are moved from RAM to CPU multiple times during calibration. 

Similarly, the \textit{calib\_cal} step is more dependent on memory throughput than on CPU speed as this step moves data to and from memory frequently. This step also does minimization looping over the dataset. As the dataset does not fit in the cache, parts of it need to be constantly moving from memory and back. Figure \ref{fig:ch4_calib_cal_cache} shows that the machine with the smallest LLC cache runs the \textit{calib\_cal} step the fastest. This is likely a combination of the benefit of faster RAM and poor cache optimization for this software. The same effect is much less pronounced in Figure \ref{fig:ch4_gsmcal_cache}, suggesting that software optimization at least plays a part in the outliers for the laptop machine. 

\subsection{Recommendations}
Based on these results, the top hardware recommendation is that \textit{prefactor}'s slowest steps can be accelerated by running on machines with faster memory or upgrading the memory of the current machines. The two slowest \textit{prefactor} steps showed improvements on machines with faster RAM.  

One software recommendation is to improve the efficiency of the \textit{calib\_cal} step through refactoring or by replacing the software package used. Unfortunately, the software used for the \textit{gsmcal\_solve} step cannot be used for the \textit{calib\_cal} step as it is not yet able to  correct for Faraday Rotation \citep{stefcal}, making it impossible to currently use the software used by the \textit{gsmcal\_solve} step. Faraday Rotation has recently been implemented in a development version of the \textit{prefactor} pipeline and is currently undergoing testing. This version of the pipeline will be implemented by September 2018.

Additionally, the large number of data cache misses recorded for the \textit{calib\_cal} step suggests that its source code is not optimized for multi-threaded processing. Data cache misses are often encountered when multiple threads have instructions on the same cache line\footnote{A cache line is a row of cache memory which is loaded into CPU as a single unit \citep{cache_architecture} }, forcing the memory controller to move this cache line between cores \citep{cache_misses}. This can also explain the large number of stalled cycles (Fig. \ref{fig:ch4_rstall}) and low number of full issue cycles (Fig. \ref{fig:ch4_full_issue}) for the \textit{calib\_cal} step. It is recommended to further study the inefficiencies of  \textit{calib\_cal} or to replace it with a newer software. If the software processing for this step is updated, analysing the cache and CPU performance of the new software will be necessary to determine whether it efficiently uses the available computational resources. 


Finally, we discovered that compiling the software on a virtual machine did not lead to a processing slowdown. This means that the current slowest \textit{prefactor} steps are not optimized to use advanced processor instructions. Nevertheless, the resulting cross-compatibility is an encouraging result as it will allow to easily distribute pre-compiled versions of the software without increasing the processing time. We recommend continuing CVMFS deployment of LOFAR software. 


\section{Conclusions}
 
In this paper, we present a novel system for automated collection of performance data for complex software pipelines. We use this suite to study the LOFAR \textit{prefactor} pipeline. The results are discussed aiming to understand the effect of different hardware parameters on the data processing. To do so, we run the pipeline on four different machines. 

The software automatically collects performance data at the operating system level without impacting processing time. Data for each pipeline step is extracted using the OpenTSDB API, plotted and analyzed. Additionally, the \textit{pipeline\_collector} suite is easy to extend with new collectors that record more detailed time-series data for each pipeline step. The performance data is stored in the time series database OpenTSDB.

Here, we used this data to find 9 insights into the LOFAR prefactor pipeline listed in Table \ref{table:ch4_results}. The implementation details are described in \ref{sec:ch4_appendix1}.

The \textit{prefactor} pipeline is used to do the initial processing for over 3000 observations that are part of the LOFAR SKSP Tier 1 survey. However, this pipeline is also used for lots of other LOFAR datasets outside the SKSP project. We have shown that increasing the RAM throughput is the easiest way to speedup \textit{prefactor} processing. Running the \textit{calib\_cal} step on hardware with RAM faster than 4 GB/s will save up to 700k CPU hours for the 3000+ unprocessed datasets. This throughput increase will also speedup the \textit{gsmcal\_solve} step by 30\% saving an additional 400k CPU hours. This is a significant fraction of the estimated 2,400k CPU hours required to process this data with the \textit{prefactor} pipeline. 

As shown in this work, we can correlate the performance of the LOFAR software with different hardware specifications. Additionally, the datasets  can vary in size and job overheads on the compute cluster can depend on the processing parameters. All of these parameters affect the processing latency for the calibration and imaging pipelines. As such, a thorough parametric model is required to further optimize the end-to-end LOFAR processing pipeline and predict processing times on future clusters.

The design of this utility makes it easy to apply to future LOFAR pipelines. It is important to note that \textit{pipeline\_collector} is general enough that it can be used by other scientific pipelines, with no modification of the pipeline. Integrating \textit{pipeline\_collector} with a different pipeline requires only minor work. In future work, we will integrate \textit{pipeline\_collector} with \textit{ddf-pipeline}. We will use this data to create a performance model of the full LOFAR imaging pipeline \citep{lofar_prefactor,Wendy_bootes,tassesmirnov}.  including the DI step, implemented by \textit{prefactor}, and  the DD step, implemented by \textit{ddf-pipeline}. This model will make it possible to first understand and then optimize the LOFAR pipeline and suggest for hardware and software improvements. 

\input{ch4/Appendix1}

\section*{Acknowledgements}
APM would like to acknowledge the support from the NWO/DOME/IBM programme ``Big Bang Big Data: Innovating ICT as a Driver For Astronomy'', project \#628.002.001.

HJR gratefully acknowledge support from the European Research Council under the European Unions Seventh Framework Programme (FP/2007-2013)/ERC Advanced Grant NEWCLUSTERS- 321271.

JBRO acknowledges financial support from NWO Top LOFAR-CRRL project, project No. 614.001.351. 


This work was carried out on the Dutch national e-infrastructure with the support of SURF
Cooperative through grant e-infra 160022 \& 160152.

%\bibliography{bibliography}

%%\end{document}

%%
%% End of file `elsarticle-template-1-num.tex'.
