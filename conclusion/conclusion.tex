\chapter{Conclusion}

\label{ch:conclusions}

As astronomical observatories collect ever-growing data-sets, the processing challenges for these data will continue increasing. Large astronomical surveys,  expected to produce petabytes of data, can no longer be processed on a single machine or small dedicated clusters at scientific institutions.  Serving the scientific requirements of these surveys will require large scale distributed processing. 

CERN's World-Wide computing grid provides sufficient resources for such projects; however, its focus is on distributed Monte-Carlo simulations. The design choices made to tackle these computations also present some design constraints for radio astronomical processing. Namely, porting complex workflows to a grid-like environment requires a framework to distribute and monitor jobs. Furthermore, processing and reprocessing thousands of observations efficiently requires a workflow orchestration software. Our aim is to enable the 30+ petabye LOFAR Two-meter Sky Survey (LoTSS) by combining high throughpt processing infrastructure with modern workflow orchestration software. 

\section{Summary of Thesis Contributions}

This work focuses on software built to accelerate, parallelize, and automate LOFAR processing as well as the insights obtained into large scale processing of LOFAR data.  We have built a scalability model which  we use to understand the performance of LOFAR broadband processing pipelines. Our model  brings novel insights into the limits of our current pipelines, as well as suggestions to improve processing throughput. 

We have built a platform for processing a Radio Astronomy data on a heterogenous, distributed infrastructure. We exploit the data level parallelism of computationally intensive processing tasks, and our work makes several LOFAR scientific projects possible. Additionally, our insights in distributed  execution of complex pipelines is crucial for enabling large astronomical surveys. We expect distributed processing will become an increasingly important paradigm in astronomy. 

Finally, we created an automated workflow system with the goal of automatically producing high fidelity images from LOFAR observations. This system was a successful integration of industry software into Radio Astronomy, one of the goals of this thesis and its associated grant. Bringing open source tools used in industry is crucial to  keeping long lived scientific projects  maintainable and productive. Our results are the first steps in enabling large scale, automated processing of LOFAR scientific workflows.  

Our advances in understanding LOFAR processing inefficiencies, exploiting data level parallelism, and automating workflows are first steps to modernizing LOFAR scientific processing. The lessons learned in this work can be directly applied in other scientific fields tasked with  processing overwhelming data rates.  

\section{Answers to Research Questions}


\begin{addmargin}[4em]{8em}% 1em left, 2em right
    \emph{\textbf{Research Question 1:} How can we use a distributed shared infrastructure for efficient LOFAR data processing?}
\end{addmargin}

In Chapters \ref{ch:LOFAR_DSP} and \ref{ch:GRID_LRT}, we detail our success with massively distributed processing of LOFAR data. We describe the underlying platform, inherited from the High Energy Physics community and the modifications to these tools that were required to host sophisticted processing software. We detail these modifications and discuss the resulting increase in throughput. Finally, we make estimations on the processing time saved by parallelizing LOFAR data processing. The work described in these chapters is essential to producing scientific data sets at a high rate, particularly considering the high data rates produced by LOFAR.  


\begin{addmargin}[4em]{8em}% 1em left, 2em right
    \emph{\textbf{Research Question 2:}  How can we build software to effortlessly accelerate complex pipelines for Radio Astronomy?} 
\end{addmargin}

Chapters \ref{ch:AGLOW} and \ref{ch:AGLOW_CI} detail the advances in parallelizing complex scientific pipelines on a distributed shared infrastructures. We integrate a mature workflow orchestration package with distributed LOFAR processing. We discuss the need for this orchestration, as well as the abilities to support additional complex pipelines. As an example application, we build a Continuous Integration pipeline tasked with verifying and validating the initial steps of LOFAR processing. 


\begin{addmargin}[4em]{8em}% 1em left, 2em right
    \emph{\textbf{Research Question 3:} Can we automatically collect performance information during massively distributed processing and predict run times for future data sets?}
\end{addmargin}

Chapters \ref{ch:pipeline_collector} and \ref{ch:Scalability_model} describe a performance monitoring suite for LOFAR data and our scalability model for LOFAR processing. When running massively distributed processing, scientists are unable to monitor the performance of the underlying software. Collecting these statistics is necessary for understanding processing inefficiencies and suggest ways to accelerate data processing. Performance data can also be used to understand the effect of processing parameters on the resource usage of complex pipelines. We study this in detail, building a model that can be used to understand the scalability of multiple processing steps. This model shows the limitations on scientific parameters imposed by limited processing resources as well as suggestions on decreasing processing time without sacrificing scientific data quality. 

\section{Limitations}

Using the software described, the LOFAR Surveys team was able to process several petabytes of archived data and produce scientific quality images. Despite the successes of the project, several issues occasionally impede data processing and prevent rapid deployment of software pipelines.

High throughput processing of LOFAR data requires the initial processing steps to be performed at the data archive locations. A major limitation to this work is processing LOFAR data at one of the three Long Term Archive sites at Forschungszentrum J{\"u}lich, Germany. As the clusters at J{\"u}lich do not support any modern containerization software, nor any other software distribution method, deploying new software is difficult and time-consuming. Additionally, orchestrating jobs at this site requires additional integration with our tools. These limitations make it difficult to automate complex scientific pipelines on the clusters available at J{\"u}lich.

A further limitation is authentication of our processing software and authentication requirements for data access. Distributed processing of large data sets requires having access to the data at multiple locations, however the intermediate products produced by our workflows are not public and require an active x.509 certificate authorized by the LOFAR SKSP project. The current workarounds to this limitation is having active certificates at each processing location. Upcoming features of the dCache storage system, bearer tokens called macaroons, will make it possible to overcome this limitation.

Finally, our current software distribution does not assign long-term version numbers to software images and scripts, nor is there a way to store these images or cite them in related papers. Implementing these features is crucial to not only making data processing easily reproducible but also make it possible to recognize the effort put into building and distributing software images. Overcoming these limitations will enable FAIR science with LOFAR data\citep{wilkinson2016fair}.


\section{Future Work}

This work focuses on the first stages of LOFAR data processing, because of the substantial gains possible by parallelization. We take in mind the complexity of our processing workflows, the full range of scientific pipelines and the heterogeneous nature of the underlying infrastructure. Because of these factors, a wide range of astronomical pipelines can use the software presented in this work. Future automation of the large scale LoTSS processing requires deciding on data quality requirements at each step and automated re-processing strategies in case a data quality check fails. Implementing intelligent re-processing strategies will reduce the effort necessary to provide high quality large-scale surveys such as LoTSS. 

This work shows how scientists can incorporate processing hosted at scientific institutions and cloud providers to scale scientific processing horizontally. One application for large scale distributed processing is the Square kilometer Array. The Square Kilometer Array, (SKA) is a planned aperture synthesis radio telescope expected to have a total collecting area of one square kilometer. It is expected to produce more than 160 TB per day \citep{johnston2017taming}, data which needs to be promptly processed. Scaling our tools to SKA-size processing requires a federation of clusters able to handle a high throughput workload. Nevertheless, as the SKA data processing will use different software tools than LOFAR, further study is needed on the optimal processing strategy for each of the many SKA science projects.

Current and future astronomical surveys provide infrastructure for scientists to efficiently process, reprocess archival data and import it into an interactive environment. In this environment, an astronomer can study the data in detail using their tools or software packages provided to them. Our software can be included in such a science portal to make LOFAR processing easy, fast, and accessible.

In recent years, academia has begun focusing on ease of access and reproducibility of science. Science done with cutting edge instruments, such as LOFAR, tends to be time-consuming to reproduce. Barriers such as setting up a working software environment and downloading massive data-sets prevent scientists from quickly and easily reproducing the results of their peers. These barriers make it difficult to verify the accuracy of discoveries and need to be overcome in order to make astronomy more honest and transparent. Automatically building, testing, versioning and releasing docker and singularity images is critical to making science in radio astronomy easily reproducible. Creating a LOFAR science portal and integrating our tools  and software images with this portal is crucial to making Radio Astronomy both more accessible and more authoritative.
